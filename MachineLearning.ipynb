{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf165b9e",
   "metadata": {},
   "source": [
    "### Foundational Machine Learning Concepts for Social Media Analytics\n",
    "\n",
    "This notebook serves as a practical exploration of the fundamental algorithms and mathematical concepts that underpin the more complex models used in the main `twitter_analytics.ipynb` file. While the primary project focuses on sentiment analysis using deep learning, this notebook breaks down the core optimization and data manipulation techniques that are essential for any machine learning practitioner.\n",
    "\n",
    "Here, we explore:\n",
    "*   **Optimization Algorithms:** Such as the Genetic Algorithm and the Simplex method, which are foundational to understanding how models search for optimal solutions.\n",
    "*   **Dynamic Programming:** Illustrated with the Knapsack problem, this showcases a powerful technique for solving complex problems by breaking them into smaller pieces.\n",
    "*   **Linear Algebra with NumPy and Pandas:** A look at a look at matrix operations and vector mathematics, which are the building blocks of neural networks and data preprocessing pipelines.\n",
    "\n",
    "Think of this notebook as a conceptual toolkit. The principles of optimization and data handling demonstrated here are directly applicable to the challenges of cleaning,processing, and modeling the unstructured text data found in tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff009c4",
   "metadata": {},
   "source": [
    "### Foundational Machine Learning Concepts for Social Media Analytics\n",
    "\n",
    "This notebook serves as a practical exploration of the fundamental algorithms and mathematical concepts that underpin the more complex models used in the main `twitter_analytics.ipynb` file. While the primary project focuses on sentiment analysis using deep learning, this notebook breaks down the core optimization and data manipulation techniques that are essential for any machine learning practitioner.\n",
    "\n",
    "Here, we explore:\n",
    "*   **Optimization Algorithms:** Such as the Genetic Algorithm and the Simplex method, which are foundational to understanding how models search for optimal solutions.\n",
    "*   **Dynamic Programming:** Illustrated with the Knapsack problem, this showcases a powerful technique for solving complex problems by breaking them into smaller pieces.\n",
    "*   **Linear Algebra with NumPy and Pandas:** A look at matrix operations and vector mathematics, which are the building blocks of neural networks and data preprocessing pipelines.\n",
    "\n",
    "Think of this notebook as a conceptual toolkit. The principles of optimization and data handling demonstrated here are directly applicable to the challenges of cleaning,processing, and modeling the unstructured text data found in tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e9fd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "                                                best  score\n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "5  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "6  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "7  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "8  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n",
      "9  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...    -20\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "import pandas as pd\n",
    "\n",
    "def onemax(x):\n",
    "    return -sum(x)\n",
    "\n",
    "def selection(pop, scores, k=3):\n",
    "    selection_1 = randint(len(pop))\n",
    "    for ix in randint(0, len(pop), k-1):\n",
    "        if scores[ix] < scores[selection_1]:\n",
    "            selection_1 = ix\n",
    "    return pop[selection_1]\n",
    "    \n",
    "def crossover(p1, p2, r_cross):\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    if rand() < r_cross:\n",
    "        pt = randint(1, len(p1)-2)\n",
    "        c1 = p1[:pt] + p2[pt:]\n",
    "        c2 = p2[:pt] + p1[pt:]\n",
    "    return [c1, c2]\n",
    "\n",
    "def mutation(bitstring, r_mut):\n",
    "    for i in range(len(bitstring)):\n",
    "        if rand() < r_mut:\n",
    "            bitstring[i] = 1 - bitstring[i]\n",
    "            \n",
    "def genetic_algorithm(objective, n_bits, n_iter, n_pop, r_cross, r_mut):\n",
    "    pop = [randint(0,2,n_bits).tolist() for _ in range(n_pop)]\n",
    "    best, best_eval = 0, objective(pop[0])\n",
    "    for gen in range(n_iter):\n",
    "        scores = [objective(c) for c in pop]\n",
    "        for i in range(n_pop):\n",
    "            if scores[i] < best_eval:\n",
    "                best, best_eval = pop[i], scores[i]\n",
    "                #print(\">%d, new best f(%s) = %.3f\" % (gen, pop[i], scores[i]))\n",
    "        selected = [selection(pop, scores) for _ in range(n_pop)]\n",
    "        children = list()\n",
    "        for i in range(0, n_pop, 2):\n",
    "            p1, p2 = selected[i], selected[i+1]\n",
    "            for c in crossover(p1, p2, r_cross):\n",
    "                mutation(c, r_mut)\n",
    "                children.append(c)\n",
    "        pop = children\n",
    "    return [best, best_eval]\n",
    "\n",
    "n_iter = 10\n",
    "n_bits = 20\n",
    "n_pop = 100\n",
    "r_cross = 0.9\n",
    "r_mut = 1.0 / float(n_bits)\n",
    "best_list, score_list = [], []\n",
    "for i in range(n_iter):\n",
    "    best, score = genetic_algorithm(onemax, n_bits, n_iter, n_pop, r_cross, r_mut)\n",
    "    best_list.append(best)\n",
    "    score_list.append(score)\n",
    "print('Done!')\n",
    "\n",
    "results = pd.DataFrame({'best':best_list, 'score':score_list})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5950e",
   "metadata": {},
   "source": [
    "### The Genetic Algorithm\n",
    "\n",
    "The genetic algorithm is a global search optimization technique based on the principles of natural selection and biological evolution. In this program, we establish functions for the core evolutionary rules:\n",
    "\n",
    "*   **Selection:** Selects the individuals, called \"parents,\" that will contribute to the next generation.\n",
    "*   **Crossover:** Combines two parents to form \"children\" for the next generation.\n",
    "*   **Mutation:** Applies random changes to individual parents to introduce variation and form children.\n",
    "\n",
    "I found this optimization algorithm to be the most suitable for the sentiment analysis aspect of my project. It is highly accurate, whereas other methods like simulated annealing can be too dependent on randomization.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "The algorithm begins by creating a random initial population. It then evaluates all candidates in the population and creates a sequence of new populations. A tournament selection procedure is implemented in the `selection` function, which takes the population and returns a chosen parent.\n",
    "\n",
    "Next, we create the next generation using the `crossover` function. This function uses a random draw to determine if crossover occurs and then selects a valid split point. This randomization is key: `c1` and `c2` are the children created from parents `p1` and `p2` by splitting them at a random point `pt`.\n",
    "\n",
    "The `mutation` function introduces further randomization by iterating through the bitstring and flipping bits based on a random chance (`r_mut`).\n",
    "\n",
    "Finally, the algorithm proceeds to the next generation. It iterates through the population, selects parent pairs, performs crossover and mutation to create a list of children, and replaces the old population with this new generation. To test the algorithm, I used **OneMax**, an objective function that takes a bitstring and returns the negative sum of its values, guiding the algorithm to maximize the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b8727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  1  1\n",
      "1  0  1  2\n",
      "2  1  5  3\n",
      "[1 1 3]\n",
      "     0    1    2    3\n",
      "0  1.0  0.0  0.0  0.0\n",
      "1  1.0  1.0  0.0  0.0\n",
      "2  1.0  1.0  1.0  0.0\n",
      "3  1.0  1.0  1.0  1.0\n",
      "     0    1    2    3\n",
      "0  1.0  1.0  1.0  1.0\n",
      "1  0.0  1.0  1.0  1.0\n",
      "2  0.0  0.0  1.0  1.0\n",
      "3  0.0  0.0  0.0  1.0\n",
      "0    3.605551\n",
      "dtype: float64\n",
      "0    [0.5547001962252291, 0.8320502943378437]\n",
      "dtype: object\n",
      "0     5.0\n",
      "1    12.0\n",
      "dtype: float64\n",
      "0    1.0\n",
      "1    1.0\n",
      "dtype: float64\n",
      "Enter the dimension of the identity matrix: 4\n",
      "     0    1    2    3\n",
      "0  1.0  0.0  0.0  0.0\n",
      "1  0.0  1.0  0.0  0.0\n",
      "2  0.0  0.0  1.0  0.0\n",
      "3  0.0  0.0  0.0  1.0\n",
      "Using the eye() function to create an identity matrix\n",
      "     0    1    2\n",
      "0  1.0  0.0  0.0\n",
      "1  0.0  1.0  0.0\n",
      "2  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "mx = pd.DataFrame([[1,1,1], [0,1,2], [1,5,3]])\n",
    "\n",
    "print(mx)\n",
    "print(mx.values.diagonal())\n",
    "\n",
    "n = 4\n",
    "L = pd.DataFrame(np.tril(np.ones((n,n))), columns = range(n),\n",
    "                 index = range(n))\n",
    "\n",
    "U = pd.DataFrame(np.triu(np.ones((n,n))), columns = range(n),\n",
    "                 index = range(n))\n",
    "\n",
    "print(L)\n",
    "print(U)\n",
    "\n",
    "mx = pd.Series([[2,3]])\n",
    "\n",
    "mag = mx.apply(lambda x: np.linalg.norm(x))\n",
    "print(mag)\n",
    "\n",
    "unitvector = mx.apply(lambda x: x/np.linalg.norm(x))\n",
    "print(unitvector)\n",
    "\n",
    "mx = pd.Series([5,12])\n",
    "\n",
    "mag = mx.apply(lambda x: np.linalg.norm(x))\n",
    "print(mag)\n",
    "\n",
    "unitvector = mx.apply(lambda x: x/np.linalg.norm(x))\n",
    "print(unitvector)\n",
    "\n",
    "x = pd.Series([1,2,3,4,5])\n",
    "y = pd.Series([5,6,7,8,9])\n",
    "\n",
    "dimension = int(input(\"Enter the dimension of the identity matrix: \"))\n",
    "identity_matrix = pd.DataFrame(np.identity(dimension), \n",
    "                               columns = range(dimension), \n",
    "                               index = range(dimension))\n",
    "print(identity_matrix)\n",
    "\n",
    "\n",
    "print(\"Using the eye() function to create an identity matrix\")\n",
    "identity_matrix = pd.DataFrame(np.eye(3), columns = range(3), \n",
    "                               index = range(3))\n",
    "print(identity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9f229",
   "metadata": {},
   "source": [
    "### Matrices: Magnitude, Unit Vectors, and Identity Matrices\n",
    "\n",
    "I chose to explore matrices because I didn't fully understand their properties. I started by exploring NumPy's functions, such as `diagonal`, `tril` (lower-triangular), and `triu` (upper-triangular). I also created identity matrices using both `np.identity()` and `np.eye()`.\n",
    "\n",
    "The most challenging concept was the **unit vector**. A unit vector doesn't represent magnitude; instead, it uses magnitude to find a purer representation of the original vector's direction. It tells you the direction where the data is most concentrated. For instance, the magnitude of a vector `[5, 12]` is calculated as `sqrt(5^2 + 12^2)`, which is 13. You would then divide each element of the vector by 13 to get the unit vector. This process isolates direction from length.\n",
    "\n",
    "I used the `.apply()` function to perform these calculations in Pandas. While this was easier than implementing the genetic algorithm, it highlights how Pandas expands on NumPy's foundation. NumPy is excellent for structured numerical data, and Pandas enhances it with powerful tools for manipulating unstructured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c42cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -59400.000000\n",
      "         Iterations: 3\n",
      "     con: array([], dtype=float64)\n",
      "     fun: -59400.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 3\n",
      "   slack: array([   0., 1500.])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([   0.,    0., 2700.])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "c= pd.Series([-8, -12, -22]).values\n",
    "A= pd.DataFrame([[17, 27, 34], [12, 21, 15]]).values\n",
    "b= pd.Series([91800, 42000]).values\n",
    "\n",
    "R = (0, None)\n",
    "T = (0, None)\n",
    "M = (0, None)\n",
    "\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "res = linprog(c, A_ub=A, b_ub=b, bounds=(R, T, M), method='simplex', options={\"disp\":True})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a3120",
   "metadata": {},
   "source": [
    "### The Simplex Algorithm\n",
    "\n",
    "The simplex algorithm is best described through analogy as this is the most user-friendly description. Imagine a stockbroker choosing between several stocks, like Tesla, Google, and Amazon. They have a finite amount of money and want to maximize their profit. The simplex algorithm helps solve this by improving an initial feasible solution until an optimal one is found.\n",
    "\n",
    "The algorithm operates within a **feasible region**, which is like a map of all possible valid investment decisions. It starts at a corner of this region and moves to an adjacent corner that improves the **objective function** (in this case, maximizing profit). This process is repeated, moving from corner to corner, until no further improvement is possible.\n",
    "\n",
    "This program uses SciPy's `linprog` function to find the optimal solution. The key parameters are:\n",
    "*   `c`: The objective function, representing the potential profit from each stock.\n",
    "*   `A_ub` and `b_ub`: The constraints, representing the limited resources (e.g., your savings and checking accounts).\n",
    "*   `bounds`: Non-negativity constraints, ensuring the solution is realistic (you can't invest negative money).\n",
    "*   `method='simplex'`: Specifies the algorithm to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a81a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 50. 50. 50.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...  50.  50.  50.]\n",
      " [  0.   0.   0. ... 140. 140. 140.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n",
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...  50.  50.  50.]\n",
      " [  0.   0.   0. ... 140. 140. 140.]\n",
      " [  0.   0.   0. ... 390. 390. 390.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "390.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def knapsack(items, capacity):\n",
    "    n = len(items)\n",
    "    weight, value, num = zip(*items) # unpack items into separate lists for weight, value, and num\n",
    "    weight = pd.Series(weight).values\n",
    "    value = pd.Series(value).values\n",
    "    dp = np.zeros((n+1, capacity+1))\n",
    "    for i in range(1, n+1):\n",
    "        dp[i, weight[i-1]:] = np.maximum(dp[i-1, weight[i-1]:], dp[i-1, :-weight[i-1]]+value[i-1])\n",
    "        print(dp)\n",
    "    return dp[n, capacity]\n",
    "\n",
    "val = pd.DataFrame([(10, 50, 30), (70, 90, 180), (70, 250, 100)])\n",
    "knapsack(val.values, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31001b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  491  492  493  494  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...   50   50   50   50   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   495  496  497  498  499  500  \n",
      "0    0    0    0    0    0    0  \n",
      "1   50   50   50   50   50   50  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "\n",
      "[4 rows x 501 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  491  492  493  494  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...   50   50   50   50   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...  140  140  140  140   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   495  496  497  498  499  500  \n",
      "0    0    0    0    0    0    0  \n",
      "1   50   50   50   50   50   50  \n",
      "2  140  140  140  140  140  140  \n",
      "3    0    0    0    0    0    0  \n",
      "\n",
      "[4 rows x 501 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  491  492  493  494  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...   50   50   50   50   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...  140  140  140  140   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...  390  390  390  390   \n",
      "\n",
      "   495  496  497  498  499  500  \n",
      "0    0    0    0    0    0    0  \n",
      "1   50   50   50   50   50   50  \n",
      "2  140  140  140  140  140  140  \n",
      "3  390  390  390  390  390  390  \n",
      "\n",
      "[4 rows x 501 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def knapsack(items, capacity):\n",
    "    n = len(items)\n",
    "    weight, value, num = zip(*items) # unpack items into separate lists for weight, value, and num\n",
    "    weight = pd.Series(weight)\n",
    "    value = pd.Series(value)\n",
    "    dp = pd.DataFrame(0, index=range(n+1), columns=range(capacity+1))\n",
    "    for i in range(1, n+1):\n",
    "        padded_slice = np.pad(dp.iloc[i-1, :-weight[i-1]]+value[i-1], \n",
    "                              (weight[i-1], 0), 'constant', \n",
    "                              constant_values=(0))\n",
    "        dp.iloc[i, :] = np.maximum(dp.iloc[i-1, :], padded_slice)\n",
    "        print(dp)\n",
    "    return dp.loc[n, capacity]\n",
    "\n",
    "val = pd.DataFrame([(10, 50, 30), (70, 90, 180), (70, 250, 100)])\n",
    "knapsack(val.values, 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389734c",
   "metadata": {},
   "source": [
    "### The Knapsack Problem with Dynamic Programming\n",
    "\n",
    "I have another analogy for you! Imagine a thief breaks into a home with a knapsack. The home contains various items, each with its own weight and value. Jewelry might have high value but low weight, while a TV is heavy but less valuable. The thief's knapsack has a limited weight capacity, so they must choose the combination of items that maximizes their total value without exceeding the weight limit.\n",
    "\n",
    "I used **dynamic programming** to solve this. This approach divides the main problem into smaller, overlapping subproblems. It solves each subproblem just once and stores the result, typically in a table, to avoid re-computation.\n",
    "\n",
    "In this code, the DP table (`dp`) is constructed where rows represent the items available and columns represent the knapsack's capacity, from 0 to the maximum limit. The code iterates through each item and each possible weight, calculating the maximum value that can be achieved at each step. The final cell of the table contains the optimal total value.\n",
    "\n",
    "For this implementation, I adapted the logic to work with Pandas DataFrames. A key step was using `np.pad` to ensure the matrix slices were the same size, which is required for the `np.maximum` function to compare the value of adding a new item versus keeping the previous best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
